{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MicroNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harsh-ux/Traffic-Sign-Recognition/blob/main/MicroNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtXZF3WCcicm"
      },
      "source": [
        "!pip install -q kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "-tvpMRIwcokg",
        "outputId": "24c57e16-1c23-4e83-b272-ea441188d103"
      },
      "source": [
        "from google.colab import files\n",
        " \n",
        "uploaded = files.upload()\n",
        " \n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "  \n",
        "# Then move kaggle.json into the folder where the API expects to find it.\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7b401fce-d8c2-4d0b-8102-375168ae75dc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7b401fce-d8c2-4d0b-8102-375168ae75dc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "User uploaded file \"kaggle.json\" with length 67 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZM2Dhawdw0t",
        "outputId": "a775cc82-e379-48e9-e561-bb296e0cfccd"
      },
      "source": [
        "!kaggle datasets download -d meowmeowmeowmeowmeow/gtsrb-german-traffic-sign"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading gtsrb-german-traffic-sign.zip to /content\n",
            " 97% 594M/612M [00:06<00:00, 84.5MB/s]\n",
            "100% 612M/612M [00:06<00:00, 102MB/s] \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHqYmOFSd6ut"
      },
      "source": [
        "import zipfile\n",
        "x = zipfile.ZipFile('/content/gtsrb-german-traffic-sign.zip')\n",
        "x.extractall('/content/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgEkPeQLd9bw",
        "outputId": "27a0f6d3-911a-4aec-9aa8-91a1888daae4"
      },
      "source": [
        "import os\n",
        "os.remove(\"/content/gtsrb-german-traffic-sign.zip\")\n",
        "print(\"File Removed!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File Removed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOEYj407dTP0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47ab7ce2-5def-4172-d7bb-4b3c775c0be5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUh5xlDOYS6K"
      },
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import Subset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader\n",
        " \n",
        "# once the images are loaded, how do we pre-process them before being passed into the network\n",
        "# by default, we resize the images to 32 x 32 in size\n",
        "# and normalize them to mean = 0 and standard-deviation = 1 based on statistics collected from\n",
        "# the training set\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize((48, 48)),\n",
        "    #transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.GaussianBlur(5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.3337, 0.3064, 0.3171), (0.2672, 0.2564, 0.2629))\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0-ehEs-jtCU",
        "outputId": "fe2c5068-b452-4287-b877-61cf7cd70beb"
      },
      "source": [
        "def train_val_dataset(dataset, val_split=0.25):\n",
        "    train_idx, val_idx = train_test_split(list(range(len(dataset))), test_size=val_split)\n",
        "    datasets = {}\n",
        "    datasets['train'] = Subset(dataset, train_idx)\n",
        "    datasets['val'] = Subset(dataset, val_idx)\n",
        "    return datasets\n",
        " \n",
        "#df_test = pd.read_csv('/content/Test.csv')\n",
        "#df_train = pd.read_csv('/content/Train.csv')\n",
        "#train_path = df_train.iloc[:, -1]\n",
        "#test_path = df_test.iloc[:, -1]\n",
        "#print(list(train_path))\n",
        " \n",
        "dataset = ImageFolder('/content/Train', data_transforms)\n",
        "print(len(dataset))\n",
        "datasets = train_val_dataset(dataset)\n",
        "print(len(datasets['train']))\n",
        "print(len(datasets['val']))\n",
        "dataloaders = {x:DataLoader(datasets[x],32, shuffle=True, num_workers=4) for x in ['train','val']}\n",
        "x,y = next(iter(dataloaders['train']))\n",
        "print(x.shape, y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "39209\n",
            "29406\n",
            "9803\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 3, 48, 48]) torch.Size([32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynHKXBYBDRKA"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        " \n",
        "nclasses = 43 # GTSRB as 43 classes\n",
        " \n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 1, kernel_size=1)\n",
        "        self.conv2 = nn.Conv2d(1, 29, kernel_size=5)\n",
        "        self.maxpool2 = nn.MaxPool2d(3, stride=2 , ceil_mode=True)\n",
        "        self.conv3 = nn.Conv2d(29, 59, kernel_size=3)\n",
        "        self.maxpool3 = nn.MaxPool2d(3, stride=2 , ceil_mode=True)\n",
        "        self.conv4 = nn.Conv2d(59, 74, kernel_size=3)\n",
        "        self.maxpool4 = nn.MaxPool2d(3, stride=2 , ceil_mode=True)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.conv3_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(1184, 300)\n",
        "        self.fc2 = nn.Linear(300, nclasses)\n",
        "        self.conv0_bn = nn.BatchNorm2d(3)\n",
        "        self.conv1_bn = nn.BatchNorm2d(1)\n",
        "        self.conv2_bn = nn.BatchNorm2d(29)\n",
        "        self.conv3_bn = nn.BatchNorm2d(59)\n",
        "        self.conv4_bn = nn.BatchNorm2d(74)\n",
        "        self.dense1_bn = nn.BatchNorm1d(300)\n",
        "    def forward(self, x):\n",
        "        x =  F.relu(self.conv1_bn(self.conv1(self.conv0_bn(x))))\n",
        "        x = F.relu(self.conv2_bn(self.conv2(x)))\n",
        "        x = F.relu(self.conv3_bn(self.conv3( self.maxpool2(x))))\n",
        "        x = F.relu(self.conv4_bn(self.conv4( self.maxpool3(x))))\n",
        "        x = self.maxpool4(x)        \n",
        "        x = x.view(-1, 1184)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dense1_bn(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        return F.log_softmax(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pv6IzXY5GAYw"
      },
      "source": [
        "from __future__ import print_function\n",
        "import argparse\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        " \n",
        " \n",
        "batch_size =50                                                                                                                                                                                     \n",
        "epochs = 10                                                                                                                                                                                                                                                                                                                                                                                 \n",
        "seed = 1                                                                                                                                                                                           \n",
        "log_interval=180                                                                                                                                                                                   \n",
        "data = \"data\"                                                                                                                                                                                                                                                                                                                                                                                          \n",
        "torch.manual_seed(1)                                                                                                                                                                               \n",
        "lr =0.007                                                                                                                                                                                          \n",
        "momentum = 0.8                                                                                                                                                                                     \n",
        "decay = 0.9                                                                                                                                                                                        \n",
        "step = 1000                                                                                                                                                                                        \n",
        "l2_norm = 0.00001  \n",
        "cuda = True\n",
        "resume = False\n",
        "# These may change as described in paper"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbsWyWu0GGlF"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Net()\n",
        "if  cuda: \n",
        "    model.to(device)\n",
        " \n",
        "if resume :\n",
        "    state_dict = torch.load(\"model_28.pth\")\n",
        "    model.load_state_dict(state_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVzQaMwFGNwD"
      },
      "source": [
        "def validation():\n",
        "    model.eval()\n",
        "    validation_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in dataloaders['val']:\n",
        "        data, target = Variable(data, volatile=True), Variable(target)\n",
        "        data =data.to(device)\n",
        "        target =target.to(device)\n",
        "        output = model(data)\n",
        "        validation_loss += F.nll_loss(output, target, size_average=False).item() # sum up batch loss\n",
        "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "    validation_loss /= len(dataloaders['val'].dataset)\n",
        "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.5f}%)\\n'.format(\n",
        "        validation_loss, correct, len(dataloaders['val'].dataset),\n",
        "        100. * correct / len(dataloaders['val'].dataset)))\n",
        "    return validation_loss\n",
        " \n",
        "def train(epoch , train_loader):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(dataloaders['train']):\n",
        "        data, target = Variable(data), Variable(target)\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target).cuda()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(dataloaders['train'].dataset),\n",
        "                100. * batch_idx / len(dataloaders['train']), loss.item()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjp9HLPLGWIp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bacc7621-b97a-4506-fa21-c623b68b16f8"
      },
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr , momentum=momentum, weight_decay=l2_norm, nesterov=True)\n",
        "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=decay)\n",
        " \n",
        "temp = 10\n",
        "for epoch in range(1, epochs+1):\n",
        "    train(epoch, dataloaders['train'])\n",
        "    val = validation()\n",
        "    if epoch % step :\n",
        "        scheduler.step()\n",
        "    if val < temp : \n",
        "        temp = val\n",
        "        model_file = 'model_' + str(epoch) + '.pth'\n",
        "        torch.save(model.state_dict(), model_file)\n",
        "        print('\\nSaved model to ' + model_file + '. You can run `python evaluate.py ' + model_file + '` to generate the Kaggle formatted csv file')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:39: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/29406 (0%)]\tLoss: 1.611350\n",
            "Train Epoch: 1 [5760/29406 (20%)]\tLoss: 1.817069\n",
            "Train Epoch: 1 [11520/29406 (39%)]\tLoss: 1.143993\n",
            "Train Epoch: 1 [17280/29406 (59%)]\tLoss: 1.787257\n",
            "Train Epoch: 1 [23040/29406 (78%)]\tLoss: 1.843669\n",
            "Train Epoch: 1 [28800/29406 (98%)]\tLoss: 1.996617\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Validation set: Average loss: 0.3896, Accuracy: 9389/9803 (95.77680%)\n",
            "\n",
            "\n",
            "Saved model to model_1.pth. You can run `python evaluate.py model_1.pth` to generate the Kaggle formatted csv file\n",
            "Train Epoch: 2 [0/29406 (0%)]\tLoss: 1.925807\n",
            "Train Epoch: 2 [5760/29406 (20%)]\tLoss: 1.378313\n",
            "Train Epoch: 2 [11520/29406 (39%)]\tLoss: 2.518625\n",
            "Train Epoch: 2 [17280/29406 (59%)]\tLoss: 1.825117\n",
            "Train Epoch: 2 [23040/29406 (78%)]\tLoss: 1.682228\n",
            "Train Epoch: 2 [28800/29406 (98%)]\tLoss: 1.835055\n",
            "\n",
            "Validation set: Average loss: 0.1728, Accuracy: 9750/9803 (99.45935%)\n",
            "\n",
            "\n",
            "Saved model to model_2.pth. You can run `python evaluate.py model_2.pth` to generate the Kaggle formatted csv file\n",
            "Train Epoch: 3 [0/29406 (0%)]\tLoss: 1.779407\n",
            "Train Epoch: 3 [5760/29406 (20%)]\tLoss: 1.826796\n",
            "Train Epoch: 3 [11520/29406 (39%)]\tLoss: 1.457605\n",
            "Train Epoch: 3 [17280/29406 (59%)]\tLoss: 1.687416\n",
            "Train Epoch: 3 [23040/29406 (78%)]\tLoss: 1.413066\n",
            "Train Epoch: 3 [28800/29406 (98%)]\tLoss: 2.054653\n",
            "\n",
            "Validation set: Average loss: 0.1439, Accuracy: 9675/9803 (98.69427%)\n",
            "\n",
            "\n",
            "Saved model to model_3.pth. You can run `python evaluate.py model_3.pth` to generate the Kaggle formatted csv file\n",
            "Train Epoch: 4 [0/29406 (0%)]\tLoss: 2.029153\n",
            "Train Epoch: 4 [5760/29406 (20%)]\tLoss: 1.299031\n",
            "Train Epoch: 4 [11520/29406 (39%)]\tLoss: 1.573259\n",
            "Train Epoch: 4 [17280/29406 (59%)]\tLoss: 1.493313\n",
            "Train Epoch: 4 [23040/29406 (78%)]\tLoss: 1.483244\n",
            "Train Epoch: 4 [28800/29406 (98%)]\tLoss: 1.113853\n",
            "\n",
            "Validation set: Average loss: 0.2679, Accuracy: 9636/9803 (98.29644%)\n",
            "\n",
            "Train Epoch: 5 [0/29406 (0%)]\tLoss: 1.884671\n",
            "Train Epoch: 5 [5760/29406 (20%)]\tLoss: 1.597547\n",
            "Train Epoch: 5 [11520/29406 (39%)]\tLoss: 1.281337\n",
            "Train Epoch: 5 [17280/29406 (59%)]\tLoss: 1.576901\n",
            "Train Epoch: 5 [23040/29406 (78%)]\tLoss: 1.584172\n",
            "Train Epoch: 5 [28800/29406 (98%)]\tLoss: 1.597768\n",
            "\n",
            "Validation set: Average loss: 0.0916, Accuracy: 9760/9803 (99.56136%)\n",
            "\n",
            "\n",
            "Saved model to model_5.pth. You can run `python evaluate.py model_5.pth` to generate the Kaggle formatted csv file\n",
            "Train Epoch: 6 [0/29406 (0%)]\tLoss: 1.531216\n",
            "Train Epoch: 6 [5760/29406 (20%)]\tLoss: 1.594855\n",
            "Train Epoch: 6 [11520/29406 (39%)]\tLoss: 1.349976\n",
            "Train Epoch: 6 [17280/29406 (59%)]\tLoss: 1.115958\n",
            "Train Epoch: 6 [23040/29406 (78%)]\tLoss: 1.876667\n",
            "Train Epoch: 6 [28800/29406 (98%)]\tLoss: 2.117948\n",
            "\n",
            "Validation set: Average loss: 0.0788, Accuracy: 9766/9803 (99.62257%)\n",
            "\n",
            "\n",
            "Saved model to model_6.pth. You can run `python evaluate.py model_6.pth` to generate the Kaggle formatted csv file\n",
            "Train Epoch: 7 [0/29406 (0%)]\tLoss: 1.731802\n",
            "Train Epoch: 7 [5760/29406 (20%)]\tLoss: 2.057656\n",
            "Train Epoch: 7 [11520/29406 (39%)]\tLoss: 1.550815\n",
            "Train Epoch: 7 [17280/29406 (59%)]\tLoss: 1.687643\n",
            "Train Epoch: 7 [23040/29406 (78%)]\tLoss: 1.709739\n",
            "Train Epoch: 7 [28800/29406 (98%)]\tLoss: 1.083272\n",
            "\n",
            "Validation set: Average loss: 0.0736, Accuracy: 9771/9803 (99.67357%)\n",
            "\n",
            "\n",
            "Saved model to model_7.pth. You can run `python evaluate.py model_7.pth` to generate the Kaggle formatted csv file\n",
            "Train Epoch: 8 [0/29406 (0%)]\tLoss: 1.467535\n",
            "Train Epoch: 8 [5760/29406 (20%)]\tLoss: 1.318079\n",
            "Train Epoch: 8 [11520/29406 (39%)]\tLoss: 1.623471\n",
            "Train Epoch: 8 [17280/29406 (59%)]\tLoss: 1.498347\n",
            "Train Epoch: 8 [23040/29406 (78%)]\tLoss: 1.962081\n",
            "Train Epoch: 8 [28800/29406 (98%)]\tLoss: 1.163032\n",
            "\n",
            "Validation set: Average loss: 0.0726, Accuracy: 9774/9803 (99.70417%)\n",
            "\n",
            "\n",
            "Saved model to model_8.pth. You can run `python evaluate.py model_8.pth` to generate the Kaggle formatted csv file\n",
            "Train Epoch: 9 [0/29406 (0%)]\tLoss: 1.481453\n",
            "Train Epoch: 9 [5760/29406 (20%)]\tLoss: 1.291746\n",
            "Train Epoch: 9 [11520/29406 (39%)]\tLoss: 1.568431\n",
            "Train Epoch: 9 [17280/29406 (59%)]\tLoss: 1.286149\n",
            "Train Epoch: 9 [23040/29406 (78%)]\tLoss: 1.902302\n",
            "Train Epoch: 9 [28800/29406 (98%)]\tLoss: 2.166237\n",
            "\n",
            "Validation set: Average loss: 0.0518, Accuracy: 9780/9803 (99.76538%)\n",
            "\n",
            "\n",
            "Saved model to model_9.pth. You can run `python evaluate.py model_9.pth` to generate the Kaggle formatted csv file\n",
            "Train Epoch: 10 [0/29406 (0%)]\tLoss: 1.757003\n",
            "Train Epoch: 10 [5760/29406 (20%)]\tLoss: 1.442923\n",
            "Train Epoch: 10 [11520/29406 (39%)]\tLoss: 1.511594\n",
            "Train Epoch: 10 [17280/29406 (59%)]\tLoss: 1.880219\n",
            "Train Epoch: 10 [23040/29406 (78%)]\tLoss: 1.264395\n",
            "Train Epoch: 10 [28800/29406 (98%)]\tLoss: 1.337321\n",
            "\n",
            "Validation set: Average loss: 0.0548, Accuracy: 9778/9803 (99.74497%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}